{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Import different libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import paths\n",
    "BASE_PATH = \"../\"\n",
    "DATA = os.path.join(BASE_PATH, \"data\")\n",
    "DATA_TRAIN = os.path.join(DATA, \"train\")\n",
    "DATA_VALIDATION = os.path.join(DATA, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters setup\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16933 images belonging to 5 classes.\n",
      "Found 4232 images belonging to 5 classes.\n",
      "Classes trouvées : {'covid': 0, 'lung_opacity': 1, 'normal': 2, 'pneumonia': 3, 'trash': 4}\n",
      "Nombre d'images d'entraînement : 16933\n",
      "Nombre d'images de validation : 4232\n"
     ]
    }
   ],
   "source": [
    "# Prepare data generator with split for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% of data will be used for validation set\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_TRAIN,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',  #80% for training\n",
    "    classes=['covid', 'lung_opacity', 'normal', 'pneumonia', 'trash']\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATA_TRAIN,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # 20% for validation\n",
    "    classes=['covid', 'lung_opacity', 'normal', 'pneumonia', 'trash']\n",
    ")\n",
    "\n",
    "# Print classes\n",
    "print(\"Classes trouvées :\", train_generator.class_indices)\n",
    "\n",
    "# print number of images in each generator\n",
    "print(f\"Nombre d'images d'entraînement : {train_generator.samples}\")\n",
    "print(f\"Nombre d'images de validation : {validation_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tom\\anaconda3\\envs\\pulmoScan4\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tom\\anaconda3\\envs\\pulmoScan4\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 289ms/step - accuracy: 0.5868 - loss: 1.0222 - val_accuracy: 0.7261 - val_loss: 0.6649\n",
      "Epoch 2/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 283ms/step - accuracy: 0.7177 - loss: 0.6951 - val_accuracy: 0.7578 - val_loss: 0.6469\n",
      "Epoch 3/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 283ms/step - accuracy: 0.7778 - loss: 0.5735 - val_accuracy: 0.8176 - val_loss: 0.4834\n",
      "Epoch 4/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 281ms/step - accuracy: 0.7994 - loss: 0.5223 - val_accuracy: 0.8197 - val_loss: 0.4870\n",
      "Epoch 5/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 282ms/step - accuracy: 0.8186 - loss: 0.4764 - val_accuracy: 0.8256 - val_loss: 0.4757\n",
      "Epoch 6/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 281ms/step - accuracy: 0.8292 - loss: 0.4455 - val_accuracy: 0.8462 - val_loss: 0.4011\n",
      "Epoch 7/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 280ms/step - accuracy: 0.8425 - loss: 0.4093 - val_accuracy: 0.8528 - val_loss: 0.4066\n",
      "Epoch 8/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 284ms/step - accuracy: 0.8560 - loss: 0.3831 - val_accuracy: 0.8738 - val_loss: 0.3506\n",
      "Epoch 9/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 289ms/step - accuracy: 0.8627 - loss: 0.3668 - val_accuracy: 0.8689 - val_loss: 0.3604\n",
      "Epoch 10/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 289ms/step - accuracy: 0.8716 - loss: 0.3400 - val_accuracy: 0.8703 - val_loss: 0.3554\n",
      "Epoch 11/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 288ms/step - accuracy: 0.8751 - loss: 0.3250 - val_accuracy: 0.8771 - val_loss: 0.3292\n",
      "Epoch 12/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 291ms/step - accuracy: 0.8862 - loss: 0.3126 - val_accuracy: 0.8809 - val_loss: 0.3305\n",
      "Epoch 13/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 286ms/step - accuracy: 0.8873 - loss: 0.3008 - val_accuracy: 0.8757 - val_loss: 0.3529\n",
      "Epoch 14/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 285ms/step - accuracy: 0.8870 - loss: 0.2983 - val_accuracy: 0.8882 - val_loss: 0.3165\n",
      "Epoch 15/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 283ms/step - accuracy: 0.8893 - loss: 0.2955 - val_accuracy: 0.8911 - val_loss: 0.3330\n",
      "Epoch 16/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 285ms/step - accuracy: 0.8899 - loss: 0.2908 - val_accuracy: 0.8925 - val_loss: 0.3274\n",
      "Epoch 17/20\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 283ms/step - accuracy: 0.8979 - loss: 0.2739 - val_accuracy: 0.8767 - val_loss: 0.3345\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 142ms/step - accuracy: 0.8894 - loss: 0.3064\n",
      "Validation accuracy: 88.54%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ÉEvalute the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('../models/cnn_model.h5')\n",
    "\n",
    "# Convert the model to a pickle file\n",
    "with open('../models/cnn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulmoScan4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
